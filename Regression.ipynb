{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOflxZF18ofd4OZTkdl30o2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hosseinm/Interview/blob/main/Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUwGeR67JKro"
      },
      "source": [
        "'''Regression with PyTorch.'''\n",
        "from __future__ import print_function\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import argparse\n",
        "import math\n",
        "import pdb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from google.colab import drive # importing data from my google drive to colab\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqNhX9-0JTk_"
      },
      "source": [
        "batchsize = 2000\n",
        "epochs = 400\n",
        "lr = 0.1\n",
        "train_loss = 0\n",
        "torch.manual_seed(1)    # reproducible\n",
        "class FeatureDataset(Dataset):\n",
        "\n",
        "    def __init__(self, csv_file):\n",
        "        self.data_frame = pd.read_csv(csv_file)\n",
        "    def __len__(self):\n",
        "        return len(self.data_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        m_data = self.data_frame.iloc[idx, :10]\n",
        "        label = self.data_frame.iloc[idx, -1]\n",
        "        if len(m_data)<10:\n",
        "            label = 0\n",
        "        label = np.array(label).astype(np.float32)\n",
        "        m_data = np.array(m_data).astype(np.float32)\n",
        "        m_data = torch.from_numpy(m_data)\n",
        "        label = torch.from_numpy(label)\n",
        "        return m_data, label\n",
        "\n",
        "trainloader_all = FeatureDataset(csv_file='/content/gdrive/MyDrive/datascience/ML/train.csv')# Add the train data address\n",
        "testloader_all = FeatureDataset(csv_file='/content/gdrive/MyDrive/datascience/ML/test.csv')  # add test data address\n",
        "trainloader = DataLoader(trainloader_all, batch_size= batchsize,\n",
        "                        shuffle=True)\n",
        "testloader = DataLoader(testloader_all, batch_size=batchsize,\n",
        "                        shuffle=True)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "best_acc = 0  # best test accuracy\n",
        "print(device)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Yn39YgFShP7"
      },
      "source": [
        "\n",
        "# this is one way to define a network\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, n_feature, n_output):\n",
        "        super(Net, self).__init__()\n",
        "        self.linear1 = nn.Linear(in_features=n_feature, out_features=20)\n",
        "        self.bn1 = nn.BatchNorm1d(num_features=20)\n",
        "        self.linear2 = nn.Linear(in_features=20, out_features=10)\n",
        "        self.bn2 = nn.BatchNorm1d(num_features=10)\n",
        "        self.linear3 = nn.Linear(in_features=10, out_features = n_output)       \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.linear1(x)))\n",
        "        x = F.relu(self.bn2(self.linear2(x)))    # activation function for hidden layer\n",
        "        x = self.linear3(x)             # linear output\n",
        "        return x\n",
        "\n",
        "net = Net(n_feature=10, n_output=1)     # define the network\n",
        "optimizer = torch.optim.Adadelta(filter(lambda p: p.requires_grad, net.parameters()), lr= lr, weight_decay=5e-4)\n",
        "loss_func = torch.nn.L1Loss() # definr loss function\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x8Ll42PecqI"
      },
      "source": [
        "####Train#####\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    net.to(device)\n",
        "    best_mae = 100\n",
        "    train_loss = 0\n",
        "    for batch_idx, (ii, targets) in enumerate(trainloader):\n",
        "        ii, targets = ii.to(device), targets.to(device)\n",
        "        feat = net(ii)\n",
        "        loss = loss_func(feat.squeeze(1),targets)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    mae = train_loss / len(trainloader)\n",
        "    print(\"Train: epoch number : \", epoch , \"Train MAE:\", mae)\n",
        "    f = open(\"result.txt\", \"a\") \n",
        "    f.write(str(train_loss))\n",
        "    f.write(str(mae))\n",
        "    f.write('\\n')\n",
        "    f.close()\n",
        "    if mae < best_mae:\n",
        "      #### Save model######\n",
        "      torch.save({'epoch': epoch, 'model': net,'model_state_dict': net.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'loss': loss}, 'checkpoint.pt')    \n",
        "      best_mae = mae\n",
        "    return train_loss, mae\n",
        "print(\"Train\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    lr = lr * (0.1 ** (epoch // 20))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr       \n",
        "    train_loss,mae = train(epoch)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNkEPziATimj"
      },
      "source": [
        "### run train/test####\n",
        "\n",
        "def test(epoch):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    net.eval()\n",
        "    data_test = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (ii, targets) in enumerate(testloader):\n",
        "            ii, targets = ii.to(device), targets.to(device)            \n",
        "            feat = net(ii)\n",
        "            label = feat.squeeze(1)\n",
        "            data_test = np.append(data_test, label.detach().cpu().numpy(), axis=0)\n",
        "    return data_test\n",
        "print(\"Train/Test\")\n",
        "\n",
        "     \n",
        "label = test(epoch)\n",
        "np.savetxt('test_pred.csv', label, delimiter=',', fmt='%d' , header='Y')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V--j4hsRZmwu"
      },
      "source": [
        "############ Using pre-trained model for data with label Y and compute MAE ###############\n",
        "## the model saved in checkpoint.pt \n",
        "\n",
        "\"\"\"def test_pretarin(epoch):\n",
        "    global best_acc\n",
        "    test_loss = 0\n",
        "    best_mae = 100\n",
        "    data1 = []\n",
        "    model = Net(n_feature=10, n_hidden=2, n_output=1)\n",
        "    checkpoint = torch.load('checkpoint.pt')\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch_idx, (ii, targets) in enumerate(testloader):\n",
        "            ii, targets = ii.to(device), targets.to(device)\n",
        "            feat = model(ii)\n",
        "            loss = loss_func(feat.squeeze(1), targets)\n",
        "            test_loss += loss.item()\n",
        "            label = feat.squeeze(1)\n",
        "            data_test = np.append(data_test, label.detach().cpu().numpy(), axis=0)\n",
        "\n",
        "    mae = test_loss / len(testloader)\n",
        "    print(\"Test: epoch number : \", epoch, 'Test MAE: ', mae)        \n",
        "    return test_loss, mae\n",
        "\n",
        "\n",
        "test_loss, best_mae = test_pretarin(0)\n",
        "np.savetxt('test_pred_with_label.csv', label, delimiter=',', fmt='%d' , header='Y')\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}